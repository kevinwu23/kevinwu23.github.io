<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.4/dist/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.7/css/all.min.css">
    <base href="https://kevinwu23.github.io">
    <title>Kevin Wu | Medical AI @ Stanford</title>
    <style>
        body {
            margin-top: 20px;
            margin-bottom: 30px;
            font-family: sans-serif;
            font-weight: lighter;
        }

        a {
            color: black;
            border-bottom: 1px dotted black;
        }

        a:hover,
        a:active {
            color: #DB522F;
            text-decoration: none;
        }

        h1 a {
            color: #6B747C;
            border: none;
        }

        h2 {
            font-size: 1.5em;
            border-bottom: 2px solid;
        }

        h3 {
            font-size: 1.2em;
            color: #000000;
        }

        h4 {
            font-size: 1em;
            font-family: sans-serif;
            font-weight: lighter;
            color: #000000;
            margin-top: 10px;
            margin-bottom: 30px;
        }

        .strong {
            color: #DB522F;
        }

        @media (max-width: 767.98px) {
            header {
                text-align: center;
            }
        }

        ul.social-icons {
            font-size: 1rem;
            margin-top: 24px;
            margin-bottom: 0;
        }

        ul.social-icons li::before {
            content: '[';
        }

        ul.social-icons li::after {
            content: ']';
        }

        ul.social-icons li a {
            border: none;
        }

        img.portrait {
            max-width: 100%;
        }

        @media (max-width: 767.98px) {
            img.portrait {
                display: block;
                max-width: 300px;
                margin: auto;
            }
        }

        .annotation {
            margin-top: -0.5em;
            margin-bottom: 0.5em;
            font-size: 12px;
            line-height: 12px;
        }

        .taxonomy img {
            max-width: 100%;
        }

        div.research-project {
            font-size: 14px;
            margin-bottom: 1.5rem;
        }

        div.line-of-research {
            background-color: #F0F0F0;
        }

        div.research-project video {
            max-width: 100%;
            margin-bottom: 0.5rem;
        }

        div.research-project p {
            margin-bottom: 0.3rem;
        }

        .news {
            font-size: 15px;
            margin-bottom: 0px;
        }

        #news-more {
            display: none;
        }

        .tweets {
            overflow: auto;
            -webkit-overflow-scrolling: touch;
        }

        .info {
            border-style: none;
            font-weight: bold;
            color: #999;
        }

        hr.dash {
            border-top: 1px dashed #bbbbbb;
            margin-bottom: 15px;
            margin-top: 15px;
        }

        .switch {
            position: relative;
            display: block;
            width: 32px;
            height: 18px;
            float: left;
			top: 3px;
        }

        .slider {
            position: absolute;
            cursor: pointer;
            top: 3px;
            right: 0;
            bottom: -3px;
            left: 0;
            background-color: #ccc;
            transition: 0.5s;
        }

        .slider:before {
            position: absolute;
            content: "";
            height: 12px;
            width: 12px;
            left: 3px;
            bottom: 3px;
            background-color: white;
            transition: 0.5s;
        }

        .active .slider {
            background-color: #DB522F;
        }

        .active .slider:before {
            transform: translateX(14px);
        }
		
		.slider.round {
		  border-radius: 34px;
		}

		.slider.round:before {
		  border-radius: 50%;
		}
    </style>
	
	<!-- Google Tag Manager -->
	<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
	new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
	j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
	'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
	})(window,document,'script','dataLayer','GTM-NZMWXMST');</script>
	<!-- End Google Tag Manager -->


    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/ns.html?id=GTM-NZMWXMST"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'UA-48610112-3');
    </script>

</head>

<body>
	
	<!-- Google Tag Manager (noscript) -->
	<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NZMWXMST"
	height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
	<!-- End Google Tag Manager (noscript) -->
	
    <header class="container">
        <h1 class="float-md-left mb-0">
            <a href="/">Kevin Wu</a>
        </h1>
        <ul class="list-inline float-md-right social-icons">
            <li class="list-inline-item"><a href="/CV_KevinWu.pdf">CV/Resume</a></li>
            <li class="list-inline-item"><a href="https://scholar.google.com/citations?user=s4dCi5sAAAAJ&hl=en">Google
                    Scholar</a></li>
            <li class="list-inline-item"><a href="https://github.com/kevinwu23">Github</a></li>
            <li class="list-inline-item"><a href="https://twitter.com/kevinywu">Twitter</a></li>
            <li class="list-inline-item"><a class="email-anchor">Email</a></li>
        </ul>
        <div class="clearfix"></div>
        <hr>
    </header>

    <div class="container">
        <div class="row mb-3">
            <div class="col-xl-8 col-lg-9 col-md-8">
                <p>
                    I'm a 4th year PhD at Stanford University working with Prof. <a href="http://james-zou.com/">James Zou</a>. I'm currently supported by the Stanford Data Science Scholars program. 
                </p>
                <p>
			My research interests lie in the application of machine learning across the translational pipeline in medicine, from pre-clinical data to the deployment of models.
                </p>
				
					
            </div>
            <div class="offset-xl-1 col-lg-3 col-md-4">
                <img src="/website/image/2023-headshot.png" class="portrait" alt="a picture of kevin wu">
            </div>
        </div>


        <div class="row">
            <!-- left column -->
            <div class="col-lg-8 mb-2">
                <h2>
                    Research
					<!--
                    <div class="float-right">
                        <small class="ml-2">by category</small>
                        <div class="switch sort-by-date">
                            <span class="slider round"></span>
                        </div>
                    </div>
					-->
                </h2>
				 
                <div class="research-projects">
					
					
                <div class="row research-project" data-sort="2023-07-01">
                    <div class="col-md-4">
				<img src="/website/image/ai_usage.png" class="portrait" alt="AI Usage">	   
                    </div>
                    <div class="col-md-8">
                        <h6>
							Characterizing the Clinical Adoption of Medical AI Devices through U.S. Insurance Claims
                        </h6>
                        <p class="text-muted">
                            <b>Kevin Wu</b>, Eric Wu, Brandon Theodorou, Weixin Liang, Christina Mack, Lucas Glass, Jimeng Sun, and James Zou, <i>NEJM AI</i><br />
                        </p>
                        
                        <p>
							We analyze billions of insurance claims data to produce a first-look at medical AI adoption.
                        </p>
			<p class="text-muted">
                            <a class="info" href="https://onepub-media.nejmgroup-production.org/ai/media/b35da8b4-b078-492b-ae20-bf938063e91f.pdf">[PDF]</a>
                        </p>
			<p class="text-muted">
                            Press: <a class="info" href="https://www.nature.com/articles/d41591-023-00098-4f">[Nature Medicine]</a>
				<a class="info" href="https://theimagingwire.com/2023/11/15/diffusion-of-medical-ai/">[The Imaging Wire]</a>
				<a class="info" href="https://cardiacwire.com/newsletter/medtronics-rdn-approval-cardiology-ai-leads-cpt-claims/">[Cardiac Wire]</a>
                        </p>
			    
                    </div>
					
					<div class="col-md-12"> 
						<hr class="dash">
					</div>
                </div>
					
				
		<div class="row research-project" data-sort="2023-07-01">
                    <div class="col-md-4">
				<img src="/website/image/data_inf.png" class="portrait" alt="DataInf">	   
                    </div>
                    <div class="col-md-8">
                        <h6>
			DataInf: Efficiently Estimating Data Influence in LoRA-tuned LLMs and Diffusion Models
                        </h6>
                        <p class="text-muted">
                            Yongchan Kwon<sup>*</sup>, Eric Wu<sup>*</sup>, <b>Kevin Wu<sup>*</sup></b>, and James Zou, <i>Under Submission</i><br />
                        </p>
                        
                        <p>
				We propose a significantly faster approximation method for estimating influence scores that is well-suited for LoRA fine-tuned large language models.  
                        </p>
			<p class="text-muted">
                            <a class="info" href="https://arxiv.org/pdf/2310.00902.pdf">[PDF]</a>
                        </p>
			    
                    </div>
					
					<div class="col-md-12"> 
						<hr class="dash">
					</div>
                </div>

		<div class="row research-project" data-sort="2023-07-01">
                    <div class="col-md-4">
				<img src="/website/image/latent-missingness.png" class="portrait" alt="OD-SHAP">	   
                    </div>
                    <div class="col-md-8">
                        <h6>
			Collecting data when missingness is unknown: a method for improving model performance given under-reporting in patient populations
                        </h6>
                        <p class="text-muted">
                            <b>Kevin Wu</b>, Dominik Dahlem, Christopher Hane, Eran Halperin, and James Zou, <i>CHIL 2023</i><br />
                        </p>
                        
                        <p>
			We propose a model-guided method for data collection when missingness is unknown, and the model is fixed. Work completed with Optum Labs.
                        </p>
			<p class="text-muted">
                            <a class="info" href="https://proceedings.mlr.press/v209/wu23b/wu23b.pdff">[PDF]</a>
                        </p>
			    
                    </div>
					
					<div class="col-md-12"> 
						<hr class="dash">
					</div>
                </div>

            </div>
            </div>
            <!-- /left column -->
            <!-- right column -->
            <div class="col-lg-4 mb-2">
				
                <h2>Talks & Presentations</h2>
                <ul class="news" style="font-size: 13px">
		<li>Dec 4, 2023: AI & Health Regulatory Policy Conference (Panelist)</li>
		<li>June 23, 2023: Conference on Health, Inference, and Learning (Oral Presentation)</li>
		<li>Apr 4, 2022: American Association for Cancer Research, Emerging Topics in Computational Oncology (Oral Presentation)</li>

                </ul>
                <a id="toggle-more-news" href="#">More &gt;</a>
				<br/>
				<br/>
				
				<br/>
	
				<br/>
                <h2>Press</h2>
                <ul class="news" style="font-size: 13px">
					<li>TechCrunch: <a href="https://techcrunch.com/2018/10/15/new-tech-lets-robots-feel-their-environment/">This robot uses lasers to ‘listen’ to its environment</a></li>
					<li>Hackaday: <a href="https://hackaday.com/2018/10/22/vibrosight-hears-when-you-are-sleeping-it-knows-when-youre-awake/">Vibrosight hears when you are sleeping. It knows when you're awake</a></li>
					<li>Fast Company: <a href="https://www.fastcompany.com/90168954/turn-your-wall-into-a-touchscreen-for-20">Turn Your Wall Into A Touch Screen For $20</a></li>
					<li>NBC News: <a href="https://www.nbcnews.com/mach/science/new-smart-wall-lets-you-control-your-home-swipes-taps-ncna869006">New smart wall lets you control your home with swipes, taps</a></li>
					<li>Engadget: <a href="https://www.engadget.com/2018/04/24/touch-sensitive-wall-control-home-devices/">Touch-sensitive wall might let you control home devices in the future</a></li>
					<li>Digital Trends: <a href="https://www.digitaltrends.com/cool-tech/carnegie-mellon-smart-walls/">This conductive paint transforms regular walls into giant touchpads</a></li>
					<li>The Verge: <a href="https://www.theverge.com/circuitbreaker/2018/4/28/17289976/smart-wall-carnegie-mellon-disney-home">You may soon be able to control your home with a smart wall</a></li>
					<li>Architect Magazine: <a href="https://www.architectmagazine.com/technology/transforming-walls-into-smart-surfaces_o">Transforming Walls into Smart Surfaces</a></li>
					<li>Science Magazine: <a href="https://www.sciencemag.org/news/2018/04/watch-researchers-turn-wall-alexa-s-eyes-and-ears">Watch researchers turn a wall into Alexa’s eyes and ears</a></li>
					<li>MIT Technology Review: <a href="https://www.technologyreview.com/s/604337/a-cheap-simple-way-to-make-anything-a-touch-pad/">A Cheap, Simple Way to Make Anything a Touch Pad</a></li>
					<li>New Scientist: <a href="https://www.newscientist.com/article/2130534-spray-on-touch-controls-give-an-interactive-twist-to-any-surface/">Spray-on touch controls give an interactive twist to any surface</a></li>
					<li>The Wall Street Journal: <a href="https://www.wsj.com/articles/how-to-turn-anything-into-a-touchpad-1494604386">How to Turn Anything into a Touchpad</a></li>
					<li>The Verge: <a href="https://www.theverge.com/2017/5/8/15577390/electrick-spray-on-touch-controls-future-interfaces-group">Electrick lets you spray touch controls onto any object or surface</a></li>
					<li>Engadget: <a href="https://www.engadget.com/2017/05/08/electrick-paint-touch-input/">Get ready to 'spray' touch controls onto any surface</a></li>
					<li>CNET: <a href="https://www.cnet.com/news/electrick-touchpad-spray-paint-carnegie-mellon/">Almost anything can become a touchpad with some spray paint</a></li>
					<li>Popular Science: <a href="https://www.popsci.com/why-touch-sensitive-brain-made-out-jell-o-represents-smart-idea/">What a Jell-O brain tells us about the future of human-machine interaction</a></li>
					<li>Gizmodo: <a href="https://gizmodo.com/scientists-figure-out-how-to-turn-anything-into-a-touch-1795016303">Scientists Figure Out How to Turn Anything Into a Touchscreen Using Conductive Spray Paint</a></li>
					<li>TechCrunch: <a href="https://techcrunch.com/2017/05/08/new-technique-turns-anything-into-a-touch-sensor/">New technique turns anything into a touch sensor</a></li>
					<li>Pittsburgh Post-Gazette <a href="https://www.post-gazette.com/business/tech-news/2017/06/14/Touch-sensing-technology-Electrick-pittsburgh-future-interfaces-group-cmu/stories/201706070162">Touch-sensing technology born of CMU researchers grabs companies' interest</a></li>
					<li>TechCrunch: <a href="https://techcrunch.com/2017/05/11/google-funded-super-sensor-project-brings-iot-powers-to-dumb-appliances/">Google-funded ‘super sensor’ project brings IoT powers to dumb appliances</a></li>
					<li>MIT Technology Review: <a href="https://www.technologyreview.com/s/601405/use-your-arm-as-a-smart-watch-touch-pad/">Use Your Arm as a Smart-Watch Touch Pad</a></li>
					<li>The Verge: <a href="https://www.theverge.com/circuitbreaker/2018/4/27/17289572/lumiwatch-projector-smartwatch-arm-touch-screen">New tech turns your skin into a touchscreen for your smartwatch</a></li>
					<li>Engadget: <a href="https://www.engadget.com/2016/05/05/touchscreen-skin-smartwatch-tech/">Navigate your smartwatch by touching your skin</a></li>
					<li>Gizmodo: <a href="https://gizmodo.com/this-new-skinterface-could-make-smartwatches-suck-less-1774926857">This New 'Skinterface' Could Make Smartwatches Suck Less</a></li>
					<li>CNET: <a href="https://www.cnet.com/news/skintrack-turns-your-entire-forearm-into-a-smartwatch-touchpad/">SkinTrack turns your entire forearm into a smartwatch touchpad</a></li>
					<li>WIRED: <a href="https://www.wired.com/2016/05/device-turns-arm-touchpad-heres-works/">SkinTrack Turns Your Arm Into a Touchpad</a></li>
					<li>Gizmodo: <a href="https://gizmodo.com/this-smartwatch-detects-gestures-by-watching-the-muscle-1741490619">This Smartwatch Detects Gestures By Watching the Muscles Inside Your Arm Move</a></li>
					<li>Hackaday: <a href="https://hackaday.com/2015/11/12/impedance-tomography-is-the-new-x-ray-machine/">Impedance Tomography is the new X-ray Machine</a></li>
					<li>New Scientist: <a href="https://www.newscientist.com/article/dn28475-no-touch-smartwatch-scans-the-skin-to-see-the-world-around-you/">No-touch smartwatch scans the skin to see the world around you</a></li>
					
                </ul>
				
                <div class="mt-3 tweets">
                    <a class="twitter-timeline" width="100%" height="2400" href="https://twitter.com/kevinywu">
                        Tweets by kevinywu
                    </a>
                    <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
                </div>
				
            </div>
            <!-- /right column -->
        </div>

    </div>

<footer>
    <div class="container">
		<small> &copy; 2015 - 2020 All rights reserved. Redesigned by <a href="https://www.ang.im">Ang Li</a></small>
	</div>
        
</footer>

</body>



<script src="https://cdn.jsdelivr.net/npm/jquery@3.4/dist/jquery.min.js"></script>
<script>
    $('#toggle-more-news').click(function () {
        $('#news-more').slideToggle();
        $('#news-more').is(':visible') ? $(this).text('< Hide') : $(this).text('More >');
        return false;
    });

    $(window).on('scroll', function () {
        $('video').each(function () {
            var video = this;
            var rect = video.getBoundingClientRect();

            if (
                rect.top >= 0 && rect.left >= 0 &&
                rect.bottom <= $(window).height() &&
                rect.right <= $(window).width()
            ) {
                video.play();
            } else {
                video.pause();
            }
        });
    });

    var researchProjects = $('.research-projects').html();

    var researchProjectsSorted = $('div.research-project').sort(function (a, b) {
        var contentA = $(a).attr('data-sort');
        var contentB = $(b).attr('data-sort');
        return (contentA < contentB) ? 1 : (contentA > contentB) ? -1 : 0;
    });

    $('.sort-by-date').click(function () {
        $(this).toggleClass('active');
        if ($(this).hasClass('active')) {
            $('.research-projects').html(researchProjects);
        } else {
            $('.research-projects').html(researchProjectsSorted);
        }
    });
	
	$('.research-projects').html(researchProjectsSorted);

    document.querySelectorAll('.email-anchor').forEach(function(a) {
        a.href = 'mailto:' + ['yang.zhang', 'cs.cmu.edu'].join('@');
    });
</script>

</html>
